#### 目录介绍
- 01.HashSet特点
- 02.HashSet如何去重
- 03.HashSet源码分析





### 好消息
- 博客笔记大汇总【16年3月到至今】，包括Java基础及深入知识点，Android技术博客，Python学习笔记等等，还包括平时开发中遇到的bug汇总，当然也在工作之余收集了大量的面试题，长期更新维护并且修正，持续完善……开源的文件是markdown格式的！同时也开源了生活博客，从12年起，积累共计N篇[近100万字，陆续搬到网上]，转载请注明出处，谢谢！
- **链接地址：https://github.com/yangchong211/YCBlogs**
- 如果觉得好，可以star一下，谢谢！当然也欢迎提出建议，万事起于忽微，量变引起质变！



### 01.HashSet特点
- HashSet特点说明
    - HashSet 实现了 Set 接口，不允许插入重复的元素，允许包含 null 元素，且不保证元素迭代顺序，特别是不保证该顺序恒久不变
    - HashSet 的代码十分简单，去掉注释后的代码不到两百行。HashSet 底层是通过 HashMap 来实现的。
- 案例测试
	- HashSet是根据hashCode来决定存储位置的，是通过HashMap实现的，所以对象必须实现hashCode()方法，存储的数据无序不能重复，可以存储null,但是只能存一个。
    ```
    public class DataType {
        public static void main(String[] args){
            Set<String> set = new HashSet<>();
            set.add("1");
            set.add("2");
            set.add(null);
            set.add("1");
            for(String s : set){
                System.out.println(s);
            }
        }
    }
    运行结果
    null
    1
    2
    ```





### 02.HashSet如何去重
- 在向 HashSet 添加元素时，HashSet 会将该操作转换为向 HashMap 添加键值对，如果 HashMap 中包含 key 值与待插入元素相等的键值对（hashCode() 方法返回值相等，通过 equals() 方法比较也返回 true），则待添加的键值对的 value 会覆盖原有数据，但 key 不会有所改变，因此如果向 HashSet 添加一个已存在的元素时，元素不会被存入 HashMap 中，从而实现了 HashSet 元素不重复的特征。[博客](https://github.com/yangchong211/YCBlogs)



### 03.HashSet源码分析
- 源码分析如下所示
    ```
    public class HashSet<E>
        extends AbstractSet<E>
        implements Set<E>, Cloneable, java.io.Serializable{
    
        //序列化ID
        static final long serialVersionUID = -5024744406713321676L;
    
        //HashSet 底层用 HashMap 来存放数据
        //Key值由外部传入，Value则由 HashSet 内部来维护
        private transient HashMap<E,Object> map;
    
        //HashMap 中所有键值对都共享同一个值
        //即所有存入 HashMap 的键值对都是使用这个对象作为值
        private static final Object PRESENT = new Object();
    
        //无参构造函数，HashMap 使用默认的初始化大小和装载因子
        public HashSet() {
            map = new HashMap<>();
        }
    
        //使用默认的装载因子，并以此来计算 HashMap 的初始化大小
        //+1 是为了弥补精度损失
        public HashSet(Collection<? extends E> c) {
            map = new HashMap<>(Math.max((int) (c.size()/.75f) + 1, 16));
            addAll(c);
        }
    
        //为 HashMap 自定义初始化大小和装载因子
        public HashSet(int initialCapacity, float loadFactor) {
            map = new HashMap<>(initialCapacity, loadFactor);
        }
    
        //为 HashMap 自定义初始化大小
        public HashSet(int initialCapacity) {
            map = new HashMap<>(initialCapacity);
        }
    
        //此构造函数为包访问权限，只用于对 LinkedHashSet 的支持
        HashSet(int initialCapacity, float loadFactor, boolean dummy) {
            map = new LinkedHashMap<>(initialCapacity, loadFactor);
        }
    
        //将对 HashSet 的迭代转换为对 HashMap 的 Key 值的迭代
        public Iterator<E> iterator() {
            return map.keySet().iterator();
        }
    
        //获取集合中的元素数量
        public int size() {
            return map.size();
        }
    
        //判断集合是否为空
        public boolean isEmpty() {
            return map.isEmpty();
        }
    
        //判断集合是否包含指定元素
        public boolean contains(Object o) {
            return map.containsKey(o);
        }
    
        //如果 HashSet 中不包含元素 e，则添加该元素，并返回 true
        //如果 HashSet 中包含元素 e，则不会影响 HashSet ，并返回 false
        //该方法将向 HashSet 添加元素 e 的操作转换为向 HashMap 添加键值对
        //如果 HashMap 中包含 key 值与 e 相等的结点（hashCode() 方法返回值相等，通过 equals() 方法比较也返回 true）
        //则新添加的结点的 value 会覆盖原有数据，但 key 不会有所改变
        //因此如果向 HashSet 添加一个已存在的元素时，元素不会被存入 HashMap 中
        //从而实现了 HashSet 元素不重复的特征
        public boolean add(E e) {
            return map.put(e, PRESENT)==null;
        }
    
        //移除集合中的元素 o
        //如果集合不包含元素 o，则返回 false
        public boolean remove(Object o) {
            return map.remove(o)==PRESENT;
        }
    
        //清空集合中的元素
        public void clear() {
            map.clear();
        }
    
        @SuppressWarnings("unchecked")
        public Object clone() {
            try {
                HashSet<E> newSet = (HashSet<E>) super.clone();
                newSet.map = (HashMap<E, Object>) map.clone();
                return newSet;
            } catch (CloneNotSupportedException e) {
                throw new InternalError(e);
            }
        }
    
        private void writeObject(java.io.ObjectOutputStream s)
            throws java.io.IOException {
            // Write out any hidden serialization magic
            s.defaultWriteObject();
    
            // Write out HashMap capacity and load factor
            s.writeInt(map.capacity());
            s.writeFloat(map.loadFactor());
    
            // Write out size
            s.writeInt(map.size());
    
            // Write out all elements in the proper order.
            for (E e : map.keySet())
                s.writeObject(e);
        }
    
        /**
         * Reconstitute the <tt>HashSet</tt> instance from a stream (that is,
         * deserialize it).
         */
        private void readObject(java.io.ObjectInputStream s)
            throws java.io.IOException, ClassNotFoundException {
            // Read in any hidden serialization magic
            s.defaultReadObject();
    
            // Read capacity and verify non-negative.
            int capacity = s.readInt();
            if (capacity < 0) {
                throw new InvalidObjectException("Illegal capacity: " +
                                                 capacity);
            }
    
            // Read load factor and verify positive and non NaN.
            float loadFactor = s.readFloat();
            if (loadFactor <= 0 || Float.isNaN(loadFactor)) {
                throw new InvalidObjectException("Illegal load factor: " +
                                                 loadFactor);
            }
    
            // Read size and verify non-negative.
            int size = s.readInt();
            if (size < 0) {
                throw new InvalidObjectException("Illegal size: " +
                                                 size);
            }
    
            // Set the capacity according to the size and load factor ensuring that
            // the HashMap is at least 25% full but clamping to maximum capacity.
            capacity = (int) Math.min(size * Math.min(1 / loadFactor, 4.0f),
                    HashMap.MAXIMUM_CAPACITY);
    
            // Create backing HashMap
            map = (((HashSet<?>)this) instanceof LinkedHashSet ?
                   new LinkedHashMap<E,Object>(capacity, loadFactor) :
                   new HashMap<E,Object>(capacity, loadFactor));
    
            // Read in all elements in the proper order.
            for (int i=0; i<size; i++) {
                @SuppressWarnings("unchecked")
                    E e = (E) s.readObject();
                map.put(e, PRESENT);
            }
        }

        //为了并行遍历数据源中的元素而设计的迭代器
        public Spliterator<E> spliterator() {
            return new HashMap.KeySpliterator<E,Object>(map, 0, -1, 0, 0);
        }
        
    }
    ```



### 其他介绍
#### 01.关于博客汇总链接
- 1.[技术博客汇总](https://www.jianshu.com/p/614cb839182c)
- 2.[开源项目汇总](https://blog.csdn.net/m0_37700275/article/details/80863574)
- 3.[生活博客汇总](https://blog.csdn.net/m0_37700275/article/details/79832978)
- 4.[喜马拉雅音频汇总](https://www.jianshu.com/p/f665de16d1eb)
- 5.[其他汇总](https://www.jianshu.com/p/53017c3fc75d)



#### 02.关于我的博客
- github：https://github.com/yangchong211
- 知乎：https://www.zhihu.com/people/yczbj/activities
- 简书：http://www.jianshu.com/u/b7b2c6ed9284
- csdn：http://my.csdn.net/m0_37700275
- 喜马拉雅听书：http://www.ximalaya.com/zhubo/71989305/
- 开源中国：https://my.oschina.net/zbj1618/blog
- 泡在网上的日子：http://www.jcodecraeer.com/member/content_list.php?channelid=1
- 邮箱：yangchong211@163.com
- 阿里云博客：https://yq.aliyun.com/users/article?spm=5176.100- 239.headeruserinfo.3.dT4bcV
- segmentfault头条：https://segmentfault.com/u/xiangjianyu/articles
- 掘金：https://juejin.im/user/5939433efe88c2006afa0c6e




